# SkillSwap Africa - Complete Toolkit Document

**A Comprehensive Guide to Building a Peer-to-Peer Skill Exchange Platform with WebRTC**

---

## üìë Table of Contents

1. [Technology Overview](#technology-overview)
2. [System Requirements](#system-requirements)
3. [Installation & Setup](#installation--setup)
4. [Minimal Working Example](#minimal-working-example)
5. [AI Prompts & Learning Reflections](#ai-prompts--learning-reflections)
6. [Common Issues & Solutions](#common-issues--solutions)
7. [Reference Resources](#reference-resources)

---

## üõ†Ô∏è Technology Overview

### What Technology Was Chosen?

**SkillSwap Africa** leverages a modern, cloud-native technology stack designed for rapid development and scalable deployment:

**Frontend**: React.js with Vite + TailwindCSS
- **Why**: Fast development, hot module reloading, modern component architecture, extensive ecosystem
- **Real-world use**: Uber, Netflix, Facebook, Airbnb all use React

**Backend**: Elixir Phoenix Framework (optional, can use Firebase alone)
- **Why**: Concurrent, real-time capable, fault-tolerant, built for distributed systems
- **Real-world use**: Discord, Pinterest, Activision

**Database**: Firebase Firestore + Authentication
- **Why**: Serverless, real-time sync, automatic scaling, zero infrastructure management
- **Real-world use**: Spotify, Slack, Duolingo use Firebase services

**Real-time Communication**: WebRTC
- **Why**: Direct peer-to-peer, no server needed for media, industry standard
- **Real-world use**: Zoom, Google Meet, Discord, Twitch

### Technology Choices Rationale

| Technology | Why Chosen | Alternatives Considered |
|-----------|-----------|------------------------|
| React | Component-based, large ecosystem, fast updates | Vue, Angular, Svelte |
| Firebase | Serverless, real-time, free tier | AWS Amplify, Supabase, Vercel |
| WebRTC | P2P communication, zero latency | Agora, Twilio, Vonage |
| Tailwind CSS | Utility-first, rapid design, minimal CSS | Bootstrap, Material-UI |
| Vite | Fast bundling, ESM native | Webpack, Create React App |
| Zustand | Lightweight state management | Redux, Recoil, Context API |

### End Goal

Create a **production-ready peer-to-peer skill exchange platform** that:
- Enables skill trading without monetary transactions
- Supports real-time video calls with WebRTC
- Scales to thousands of users with Firebase
- Deploys to production in minutes
- Costs $0/month to run (MVP tier)

---

## üíª System Requirements

### Operating System
- **Windows**: 10 or newer
- **macOS**: 10.13 or newer
- **Linux**: Ubuntu 18.04 or newer (Debian-based)

### Required Software

#### Node.js & npm
```bash
# Download from https://nodejs.org/
# LTS version recommended (v18+ or v20+)

# Verify installation
node --version   # v16.0.0 or higher
npm --version    # v7.0.0 or higher
```

#### Git
```bash
# Download from https://git-scm.com/
git --version    # v2.25 or higher
```

#### Text Editor
- **Recommended**: Visual Studio Code (https://code.visualstudio.com/)
- **VS Code Extensions to Install**:
  - ES7+ React/Redux/React-Native snippets
  - Tailwind CSS IntelliSense
  - Firebase Explorer
  - Thunder Client (for API testing)

#### Web Browser
- **Chrome 88+** (best WebRTC support)
- **Firefox 85+**
- **Safari 14+** (limited WebRTC, but works)
- **Edge 88+**

### Hardware Minimum
- **CPU**: Dual-core processor (Intel i5 or equivalent)
- **RAM**: 4GB minimum (8GB recommended for development)
- **Storage**: 2GB free space
- **Internet**: 5+ Mbps (for video calls)
- **Webcam & Microphone**: Required for testing video features

### Optional Tools
- **Postman** or **Thunder Client**: API testing
- **Git GUI**: TortoiseGit, GitHub Desktop (optional)
- **Docker**: For containerized deployment
- **Elixir 1.14+**: If deploying backend (optional)

### Verification Checklist
```bash
# Run these commands to verify setup
node --version        # Should be v16+
npm --version         # Should be v7+
git --version         # Should be v2.25+
npx create-vite --version  # Confirms npm works
```

---

## üîß Installation & Setup

### Step 1: Clone or Download Project

**Option A: Using Git**
```bash
git clone https://github.com/yourusername/skillswap-africa.git
cd "skillswap-africa"
```

**Option B: Direct File Access**
Navigate to your project folder:
```bash
cd "c:\Users\BONKE\Desktop\SKILLSWAP AFRICA"
```

### Step 2: Install Frontend Dependencies

```bash
cd skillswap-frontend
npm install
```

This creates a `node_modules` folder with all dependencies. Takes 2-5 minutes.

### Step 3: Configure Firebase

#### A. Create Firebase Project
1. Go to https://console.firebase.google.com
2. Click "Create a project"
3. Name it: `skillswap-africa`
4. Uncheck "Google Analytics" (optional)
5. Click "Create project" and wait 1-2 minutes



3. Click "Publish"

#### F. Update Project Configuration

Edit `skillswap-frontend/src/services/firebase.js`:

```javascript
import { initializeApp } from "firebase/app";
import { getAuth } from "firebase/auth";
import { getFirestore } from "firebase/firestore";
import { getStorage } from "firebase/storage";

const firebaseConfig = {
  apiKey: "YOUR_API_KEY_HERE",
  authDomain: "your-project.firebaseapp.com",
  projectId: "your-project-id",
  storageBucket: "your-project.appspot.com",
  messagingSenderId: "YOUR_SENDER_ID",
  appId: "YOUR_APP_ID"
};

const app = initializeApp(firebaseConfig);
export const auth = getAuth(app);
export const db = getFirestore(app);
export const storage = getStorage(app);
```

### Step 4: Create Firestore Collections

These can be created automatically when code runs, or manually:

1. **users** - User profiles
2. **sessions** - Teaching/learning sessions
3. **reviews** - Ratings and feedback
4. **creditTransactions** - Credit history
5. **safeLocations** - Physical meetup locations

### Step 5: Start Development Server

```bash
npm run dev
```

Output should show:
```
VITE v5.x.x  ready in xxx ms

  ‚ûú  Local:   http://localhost:5173/
  ‚ûú  press h + enter to show help
```

Open your browser to `http://localhost:5173`

### Step 6: Test the Setup

1. Click "Register"
2. Create account with test email
3. Complete profile
4. Add a skill to teach
5. If data appears in Firestore, setup is complete ‚úÖ

---

## üéØ Minimal Working Example: Your First Skill Match

### Simple "Hello World" Equivalent: User Registration & Skill Addition

**What this example demonstrates:**
- Firebase authentication
- Firestore database operations
- Real-time data updates
- Basic component structure

### Complete Walkthrough

#### 1. Register Account

**Step A:** Go to `http://localhost:5173` ‚Üí Click "Register"

**Step B:** Fill in form:
```
Email: learner@example.com
Password: Test1234
Name: Jane Learner
Country: Kenya
```

**Step C:** Click "Register"

**Result in Firestore:**
The `users` collection now has:
```javascript
{
  uid: "auto-generated-firebase-id",
  email: "learner@example.com",
  displayName: "Jane Learner",
  country: "Kenya",
  credits: 0,
  reputation: 0,
  skillsOffered: [],
  skillsWanted: [],
  createdAt: "2025-11-25T10:30:00Z"
}
```

#### 2. Add Skills You Want to Learn

**Step A:** Go to "Skills" page

**Step B:** In "I Want to Learn" section, type:
```
Skill: Python
Priority: High
```

**Step C:** Click "Add Skill"

**Step D:** Check Firestore ‚Üí users ‚Üí your-user-doc:

```javascript
skillsWanted: [
  {
    id: 1234567890,
    name: "Python",
    priority: "High",
    createdAt: timestamp
  }
]
```

#### 3. Add Skills You Can Teach (Using Second Account)

Repeat registration with:
```
Email: teacher@example.com
Password: Test1234
Name: John Teacher
Country: Kenya
```

Then add:
```
Skill: Python
Years of Experience: 5
```

#### 4. Find Your First Match!

**From learner account:**
1. Go to "Find Matches"
2. See John Teacher with match score
3. Click "Book Session"

**Result in Firestore ‚Üí sessions:**
```javascript
{
  id: "auto-generated",
  teacher: "john-uid",
  learner: "jane-uid",
  skillTeaching: "Python",
  skillLearning: "Python",
  sessionType: "virtual",
  status: "pending",
  createdAt: timestamp,
  credits: 1
}
```

#### 5. Start Virtual Session (WebRTC)

**What happens:**
1. Click "Join Session"
2. Browser requests camera/microphone access
3. WebRTC peer connection established
4. Real-time video call begins
5. Screen sharing available
6. End session ‚Üí credits automatically transferred

**Console output for WebRTC connection:**
```
[VideoCallComponent] RTCPeerConnection created
[VideoCallComponent] Local stream obtained
[VideoCallComponent] Offer created
[VideoCallComponent] ICE candidates being gathered...
[VideoCallComponent] Remote stream received
[VideoCallComponent] Connection state: connected ‚úì
```

### Code Example: Basic Component Structure

```jsx
// src/components/SkillAddForm.jsx - Minimal skill adding
import React, { useState } from 'react';
import { db, auth } from '../services/firebase';
import { collection, addDoc, serverTimestamp } from 'firebase/firestore';

export default function SkillAddForm() {
  const [skillName, setSkillName] = useState('');
  const [loading, setLoading] = useState(false);

  const handleAddSkill = async (e) => {
    e.preventDefault();
    setLoading(true);

    try {
      // Get current user
      const userId = auth.currentUser.uid;

      // Add skill to Firestore
      await addDoc(collection(db, 'users', userId, 'skills'), {
        name: skillName,
        createdAt: serverTimestamp(),
        verified: false
      });

      setSkillName('');
      alert('Skill added successfully!');
    } catch (error) {
      alert('Error: ' + error.message);
    } finally {
      setLoading(false);
    }
  };

  return (
    <form onSubmit={handleAddSkill}>
      <input
        type="text"
        value={skillName}
        onChange={(e) => setSkillName(e.target.value)}
        placeholder="Enter skill name"
        required
      />
      <button type="submit" disabled={loading}>
        {loading ? 'Adding...' : 'Add Skill'}
      </button>
    </form>
  );
}
```

### Expected Output

After completing these steps, you have:
1. ‚úÖ Two authenticated users
2. ‚úÖ Skills stored in Firestore
3. ‚úÖ Matching algorithm working
4. ‚úÖ Session created
5. ‚úÖ WebRTC video call working

This demonstrates the core platform loop: **Register ‚Üí Add Skills ‚Üí Find Match ‚Üí Video Call ‚Üí Credit Transfer**

---

## ü§ñ AI Prompts & Learning Reflections

### Learning Focus: WebRTC Protocol Implementation

This capstone project deeply explores WebRTC, a complex industry-critical technology. Below are the key AI prompts used to master this technology, along with evaluation and reflection.

---

### Prompt 1: WebRTC Fundamentals & Architecture

**Used**: During initial research phase (Week 1)

**Prompt Text**:
```
Explain how WebRTC works from first principles. Break down:
1. What is peer-to-peer communication and why is it important?
2. How does WebRTC establish connections between browsers?
3. What is the difference between SDP (offer/answer) and ICE?
4. What are STUN servers and TURN servers? When is each needed?
5. Why do we need a signaling server if WebRTC is P2P?

Provide examples and real-world use cases.
```

**AI Response Summary**:
- Detailed explanation of RTCPeerConnection lifecycle
- Clear distinction between signaling and media channels
- Comprehensive NAT traversal strategies
- Real-world architecture diagrams

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Excellent - Foundational Knowledge**
- Provided conceptual overview before diving into code
- Explained why each component exists
- Clarified common misconceptions about P2P
- Helped design overall system architecture

**My Reflection**:
This prompt was crucial for understanding WebRTC isn't just "turn on camera." The separation of signaling (connecting) from media (video) was mind-bending initially. Learning that STUN/TURN are just for discovering IP addresses‚Äînot for media transfer‚Äîwas enlightening.

**Key Takeaway**: WebRTC's complexity comes from NAT traversal, not the protocol itself.

---

### Prompt 2: Implementing Peer Connection in React

**Used**: During component development (Week 2)

**Prompt Text**:
```
Provide a complete React component that:
1. Initializes RTCPeerConnection with proper STUN/TURN config
2. Captures audio/video from getUserMedia()
3. Handles local video rendering
4. Handles remote video rendering from ontrack event
5. Properly cleans up resources on component unmount
6. Includes error handling for:
   - Camera/mic permission denied
   - Device not found
   - Connection failures

Include proper TypeScript/JSDoc comments. Show handling of:
- Loading states
- Error states
- Disconnection scenarios
```

**AI Response Summary**:
Production-ready component with:
- Comprehensive error handling
- Proper useEffect cleanup
- Mute/unmute functionality
- Video on/off toggle
- Connection state tracking
- Detailed comments for each step

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Excellent - Core Implementation**
- Code was directly usable in production
- Error messages were helpful for debugging
- Cleanup patterns prevented memory leaks
- Showed proper React patterns

**My Reflection**:
This was the turning point. Having a working component gave me a mental model of how WebRTC flows. The importance of cleanup (stopping tracks, closing connection) became obvious when testing. Forgetting cleanup caused memory leaks that crashed the app.

**Key Takeaway**: WebRTC requires meticulous resource management.

---

### Prompt 3: SDP Offer/Answer Exchange with Firebase Signaling

**Used**: During signaling implementation (Week 2-3)

**Prompt Text**:
```
I need to implement the SDP offer/answer model for WebRTC signaling using Firebase Firestore.

Show me:
1. How to create an offer from the initiating peer
2. How to send the offer through Firestore
3. How to receive and set the offer on the remote peer
4. How to create an answer from the remote peer
5. How to send the answer back
6. How to set the remote description on the initiating peer

Explain why order matters and what happens if you skip steps.

Also show the Firestore document structure for storing offers/answers.
```

**AI Response Summary**:
- Step-by-step flow with code
- Firestore collection schema showing:
  ```javascript
  signaling/{roomId}/offer
  signaling/{roomId}/answer
  signaling/{roomId}/iceCandidates
  ```
- Detailed explanation of SDP format
- Why timing matters
- Error handling for state violations

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Excellent - Clarified Complex Negotiation**
- Showed exact Firestore queries needed
- Explained why state matters (can't answer before receiving offer)
- Included listeners for real-time updates
- Addressed race conditions

**My Reflection**:
The "offer/answer" model is the most confusing part of WebRTC. I initially thought I could send offers bidirectionally. Learning that one peer must be initiator and the other responder was critical. The prompt clarified the asymmetry and why it's needed.

**Key Takeaway**: WebRTC negotiation is asymmetrical‚Äîinitiator and responder have different roles.

---

### Prompt 4: ICE Candidate Handling & Trickle ICE

**Used**: During debugging connection issues (Week 3)

**Prompt Text**:
```
Explain ICE candidates in WebRTC deeply:

1. What are ICE candidates? List all types (host, srflx, prflx, relay)
2. What is the difference between:
   - STUN servers (free, provide reflexive addresses)
   - TURN servers (paid, relay data)
3. How does the browser gather candidates?
4. What is "Trickle ICE" and when is it needed?
5. How do I send candidates from local peer to remote peer?
6. How do I receive and add remote candidates?

Show code for:
- Listening to icecandidate event
- Storing candidates in Firestore
- Retrieving and adding remote candidates
- Handling race conditions (candidates arriving before answer)

Why do connections fail even with candidates?
```

**AI Response Summary**:
- Detailed candidate types explanation
- Firestore pattern for queuing candidates
- Code examples for adding candidates
- Troubleshooting guide for connection failures
- Explanation of candidate trickling timing

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Excellent - Critical for Reliability**
- Showed why connections timeout (missing TURN servers)
- Explained candidate race conditions
- Provided logging patterns for debugging
- Included fallback strategies

**My Reflection**:
ICE candidates were my biggest debugging pain point. I initially didn't realize candidates could arrive before the answer. The code would crash trying to add a candidate to an uninitialized peer connection. Learning about race conditions and the need for TURN servers (my STUN-only setup failed behind NAT) was critical for reliability.

**Key Takeaway**: Robust ICE handling requires queue management and fallback TURN servers.

---

### Prompt 5: Media Stream Handling & Track Management

**Used**: During video rendering phase (Week 3-4)

**Prompt Text**:
```
Show me how to properly handle media streams and tracks in WebRTC:

1. getUserMedia constraints (resolution, frame rate, audio quality)
2. Handling permission denial gracefully
3. Fallback to audio-only if camera unavailable
4. Muting/unmuting audio tracks
5. Stopping video while keeping audio
6. Handling remote track events
7. Rendering multiple remote tracks
8. Memory leak prevention
9. Mobile-specific handling (permissions, battery)

Provide code that handles:
- Permission dialogs
- Device selection
- Track enable/disable state
- Error recovery
- Battery optimization

Also explain audio echo (feedback loop) and how to prevent it.
```

**AI Response Summary**:
- Comprehensive getUserMedia options
- Permission handling for all browsers
- Mobile-specific constraints
- Muting implementation patterns
- Echo prevention (mute local audio in video element)
- Battery optimization flags
- Graceful degradation patterns

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê **Very Good - Production Quality**
- Covered edge cases (no camera, no mic, permission denied)
- Mobile handling was crucial for platform accessibility
- Echo prevention was subtle but critical for UX
- Battery optimization shown for mobile devices

**My Reflection**:
Testing on mobile revealed constraints I missed. Frame rate and resolution needed aggressive limits on mobile. The audio echo issue was embarrassing‚ÄîI didn't realize muting the local `<video>` element was the fix. Users hear themselves through speakers otherwise.

**Key Takeaway**: WebRTC implementation must handle device constraints and platform differences.

---

### Prompt 6: Debugging Connection Failures & Network Issues

**Used**: During testing and troubleshooting (Week 4)

**Prompt Text**:
```
Help me debug WebRTC connection issues. Show me:

1. Logging patterns to track connection state:
   - When offer is created
   - When offer is set
   - When ICE candidates arrive
   - Connection state changes

2. Common failure scenarios and how to detect them:
   - Connection stuck in "connecting"
   - Offer created but no answer received
   - Candidates arriving too early
   - STUN/TURN unreachable

3. How to test locally without TURN servers
4. How to test behind NAT/firewall
5. Chrome DevTools inspection for WebRTC

6. What logs should I look for in production?

Show practical console logging code that helps diagnose:
- Missing answer
- No remote stream
- No connection established
```

**AI Response Summary**:
- Comprehensive logging patterns
- Chrome DevTools RTCStats inspector guidance
- Diagnostic flowchart
- Network simulation instructions
- Common error patterns and fixes
- Production telemetry suggestions

**Evaluation**: ‚≠ê‚≠ê‚≠ê‚≠ê **Very Good - Debugging Arsenal**
- The logging patterns saved hours of debugging
- Learning to use Chrome's WebRTC stats inspector was game-changing
- Network simulation (throttling, offline) caught edge cases
- Production logging suggestions prevent future issues

**My Reflection**:
Debugging WebRTC without proper logging is torture. Half my bugs were solved by adding detailed logging. The Chrome WebRTC stats inspector showed candidates being gathered but not reaching peer. This led me to add TURN servers, which fixed 80% of failure cases.

**Key Takeaway**: WebRTC debugging requires detailed logging and proper tools.

---

## üêõ Common Issues & Solutions

### Issue 1: "Permission Denied" When Accessing Camera/Microphone

**Error Message**:
```
NotAllowedError: Permission denied
```

**Causes**:
- User clicked "Block" on permission prompt
- Permissions revoked in browser settings
- Device doesn't have camera/microphone
- HTTPS not enabled (Chrome requires HTTPS for camera)

**Solution**:

**Step 1: Check Browser Permissions**
- Chrome: Settings ‚Üí Privacy ‚Üí Site Settings ‚Üí Camera/Microphone
- Firefox: Settings ‚Üí Privacy ‚Üí Permissions ‚Üí Camera/Microphone
- Safari: System Preferences ‚Üí Security & Privacy ‚Üí Camera/Microphone

**Step 2: Add Fallback in Code**
```javascript
async function startVideoCall() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 }
      },
      audio: true
    });
    
    localVideoRef.current.srcObject = stream;
  } catch (error) {
    if (error.name === 'NotAllowedError') {
      // Permission denied
      setStatus('Please allow camera/microphone access');
      setAudioOnly(true);
      
      // Try audio-only fallback
      try {
        const audioStream = await navigator.mediaDevices.getUserMedia({
          audio: true
        });
        // Use audio-only stream
      } catch (audioError) {
        setStatus('Camera and microphone not available');
      }
    } else if (error.name === 'NotFoundError') {
      setStatus('No camera or microphone found');
    }
  }
}
```

**Step 3: Test with Constraints**
```javascript
// Be less demanding on mobile
const constraints = {
  video: {
    width: { ideal: window.innerWidth < 768 ? 320 : 640 },
    height: { ideal: window.innerWidth < 768 ? 240 : 480 },
    frameRate: { ideal: 15 } // Lower on mobile
  },
  audio: {
    echoCancellation: true,
    noiseSuppression: true
  }
};
```

**Reference**: [MDN getUserMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)

---

### Issue 2: Peer Connection Fails to Establish ("Connecting" State Never Changes)

**Error Symptoms**:
- Connection state stuck at "connecting"
- Candidates being gathered but no connection
- Works locally, fails over internet

**Root Causes**:
- STUN servers unreachable
- TURN servers not configured
- NAT/firewall blocking ports
- One peer not receiving answer
- ICE candidate gathering incomplete

**Solution - Step by Step**:

**Step 1: Add Better STUN/TURN Configuration**
```javascript
const peerConnectionConfig = {
  iceServers: [
    // Google STUN servers (free)
    { urls: 'stun:stun1.l.google.com:19302' },
    { urls: 'stun:stun2.l.google.com:19302' },
    { urls: 'stun:stun3.l.google.com:19302' },
    { urls: 'stun:stun4.l.google.com:19302' },
    
    // Fallback TURN server (if behind strict NAT)
    {
      urls: 'turn:turnserver.example.com',
      username: 'username',
      credential: 'password'
    }
  ]
};

const peerConnection = new RTCPeerConnection(peerConnectionConfig);
```

**Step 2: Add Diagnostic Logging**
```javascript
peerConnection.addEventListener('icecandidate', (event) => {
  if (event.candidate) {
    console.log('üîÑ ICE Candidate:', {
      type: event.candidate.type,
      protocol: event.candidate.protocol,
      address: event.candidate.address,
      port: event.candidate.port
    });
    
    if (event.candidate.type === 'relay') {
      console.log('‚úÖ TURN candidate found (good for NAT)');
    }
  }
});

peerConnection.addEventListener('connectionstatechange', () => {
  console.log('üì± Connection State:', peerConnection.connectionState);
});

peerConnection.addEventListener('iceconnectionstatechange', () => {
  console.log('üßä ICE Connection State:', peerConnection.iceConnectionState);
});
```

**Step 3: Check Firestore Signal Flow**
```javascript
// Verify offer is being received
const signalDoc = await getDoc(doc(db, 'signaling', roomId));
console.log('üìÑ Signal Document:', {
  hasOffer: !!signalDoc.data()?.offer,
  hasAnswer: !!signalDoc.data()?.answer,
  candidates: signalDoc.data()?.candidates?.length || 0
});
```

**Step 4: Test with Chrome WebRTC Stats**
1. Open `chrome://webrtc-internals/`
2. Look for "RTCPeerConnection" sections
3. Check "ICE Connection State" ‚Üí should be "connected"
4. Check candidates ‚Üí should have "relay" or "srflx" types
5. If only "host" candidates ‚Üí behind strict NAT, needs TURN

**Step 5: Timeout Fallback**
```javascript
const connectionTimeout = setTimeout(() => {
  if (peerConnection.connectionState !== 'connected') {
    console.error('‚ö†Ô∏è Connection timeout after 10s');
    setStatus('Connection failed. Trying backup TURN server...');
    
    // Could reconnect with different servers or show error
  }
}, 10000);
```

**Reference**: [WebRTC ICE Configuration](https://developer.mozilla.org/en-US/docs/Web/API/RTCIceServer)

---

### Issue 3: Local Video Works, Remote Video is Black/Missing

**Error Symptoms**:
- Own video visible, peer's video is blank
- `remoteVideoRef.srcObject` is null
- ontrack event never fires

**Root Causes**:
- Remote peer's tracks not being added
- ontrack listener not set before answer
- Remote stream exists but tracks disabled
- Timing issue (listener set after track arrives)

**Solution**:

**Step 1: Ensure ontrack Listener is Set Early**
```javascript
// ‚ùå WRONG - listener set after connection established
peerConnection.createOffer();
peerConnection.setLocalDescription(offer);
// ... later ...
peerConnection.addEventListener('track', event => { }); // Too late!

// ‚úÖ CORRECT - listener set immediately
const peerConnection = new RTCPeerConnection(config);

// Set listener FIRST, before any negotiation
peerConnection.addEventListener('track', (event) => {
  console.log('üé• Remote track received:', event.track.kind);
  remoteVideoRef.current.srcObject = event.streams[0];
});

// Then do negotiation
peerConnection.createOffer();
```

**Step 2: Add Logging to Diagnose**
```javascript
peerConnection.addEventListener('track', (event) => {
  console.log('‚úÖ ontrack fired!', {
    kind: event.track.kind,
    enabled: event.track.enabled,
    streamId: event.streams[0]?.id,
    trackId: event.track.id
  });
  
  if (event.track.kind === 'video') {
    console.log('‚úÖ Video track received');
    remoteVideoRef.current.srcObject = event.streams[0];
  }
});

// Also log when tracks are added
stream.getTracks().forEach(track => {
  console.log('üì§ Adding local track:', track.kind);
  peerConnection.addTrack(track, stream);
});
```

**Step 3: Check Remote Peer is Adding Tracks**
On the remote (answerer) side:
```javascript
// This MUST happen before creating answer
const stream = await navigator.mediaDevices.getUserMedia({
  video: true,
  audio: true
});

const peerConnection = new RTCPeerConnection(config);

// Add tracks FIRST
stream.getTracks().forEach(track => {
  peerConnection.addTrack(track, stream);
});

// Then handle offer
const answer = await peerConnection.createAnswer();
await peerConnection.setLocalDescription(answer);
```

**Step 4: Test Remote Track State**
```javascript
// In video element, check if tracks are flowing
setInterval(() => {
  const stats = remoteVideoRef.current.getVideoPlaybackQuality?.();
  if (stats) {
    console.log('üé¨ Remote video stats:', {
      width: stats.width,
      height: stats.height,
      droppedFrames: stats.droppedVideoFrames,
      totalFrames: stats.totalVideoFrames
    });
  }
}, 1000);
```

**Step 5: Fallback to Audio if Video Fails**
```javascript
// After waiting 3 seconds for video
setTimeout(() => {
  if (!remoteVideoRef.current.srcObject) {
    console.warn('‚ö†Ô∏è No remote video received');
    setStatus('Remote video unavailable, using audio only');
    // Show audio-only UI
  }
}, 3000);
```

**Reference**: [RTCPeerConnection ontrack](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/ontrack)

---

### Issue 4: Audio Echo/Feedback Loop - Users Hear Themselves

**Error Symptoms**:
- User hears their own voice echoed back
- Disturbing feedback during calls
- Only happens with speaker, not headphones

**Root Cause**:
- Local audio playing from speaker
- Speaker audio captured by microphone again
- Creates feedback loop

**Solution - The Simple Fix**:

```jsx
// ‚ùå WRONG - audio plays from local video
<video 
  ref={localVideoRef} 
  autoPlay 
  muted={false}  // ‚ùå This plays audio!
  playsInline 
/>

// ‚úÖ CORRECT - mute local audio
<video 
  ref={localVideoRef} 
  autoPlay 
  muted={true}   // ‚úÖ Prevents echo
  playsInline 
/>

// Remote video - unmuted to hear peer
<video 
  ref={remoteVideoRef} 
  autoPlay 
  muted={false}  // ‚úÖ Hear the other person
  playsInline 
/>
```

**Why This Works**:
- `muted={true}` on `<video>` element prevents audio output
- User's own mic input goes to remote peer
- Remote peer's audio plays from `remoteVideoRef`
- No feedback loop

**Advanced: Echo Cancellation**
```javascript
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    echoCancellation: true,     // ‚úÖ Enable echo cancellation
    noiseSuppression: true,      // Also suppress background noise
    autoGainControl: true        // Auto adjust volume
  },
  video: true
});
```

**Reference**: [HTML Audio Muting](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#muted)

---

### Issue 5: "SyntaxError: Unexpected token < in JSON at position 0"

**Error Appears**:
In console when trying to parse Firestore data

**Root Cause**:
- Trying to parse HTML as JSON
- Firebase config not updated
- Firestore document doesn't exist

**Solution**:

**Step 1: Check Firebase Config**
```javascript
// In firebase.js, verify:
const firebaseConfig = {
  apiKey: "AIza...",  // Not a URL!
  authDomain: "skillswap-africa-xxxxx.firebaseapp.com",
  projectId: "skillswap-africa-xxxxx",
  // etc
};

// NOT this:
const firebaseConfig = "https://console.firebase.google.com/..."; // ‚ùå
```

**Step 2: Add Error Handling**
```javascript
async function getSessionData(sessionId) {
  try {
    const docRef = doc(db, 'sessions', sessionId);
    const docSnap = await getDoc(docRef);
    
    if (!docSnap.exists()) {
      console.error('Document not found:', sessionId);
      return null;
    }
    
    return docSnap.data();
  } catch (error) {
    console.error('Error fetching document:', error);
    return null;
  }
}
```

**Step 3: Verify Collections Exist**
```bash
# In Firebase Console, check:
# Firestore Database ‚Üí Collections
# Should see: users, sessions, reviews, creditTransactions
```

---

## üìö Reference Resources

### Official Documentation

#### WebRTC
- **MDN WebRTC API**: https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API
- **WebRTC Signaling & Video**: https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling
- **WebRTC Session Description**: https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Session_description
- **RTCPeerConnection**: https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection

#### React
- **React Official Docs**: https://react.dev
- **React Hooks Guide**: https://react.dev/reference/react/hooks
- **React useEffect**: https://react.dev/reference/react/useEffect

#### Firebase
- **Firebase Documentation**: https://firebase.google.com/docs
- **Firestore Guide**: https://firebase.google.com/docs/firestore
- **Firebase Auth**: https://firebase.google.com/docs/auth
- **Firestore Security Rules**: https://firebase.google.com/docs/firestore/security/start

#### CSS & UI
- **Tailwind CSS Docs**: https://tailwindcss.com/docs
- **Vite User Guide**: https://vitejs.dev/guide/

### Protocol Standards & RFCs

- **Offer/Answer Model (RFC 3264)**: https://tools.ietf.org/html/rfc3264
- **ICE Protocol (RFC 5245)**: https://tools.ietf.org/html/rfc5245
- **STUN Protocol (RFC 5389)**: https://tools.ietf.org/html/rfc5389
- **TURN Protocol (RFC 5766)**: https://tools.ietf.org/html/rfc5766

### Community & Tutorials

- **WebRTC Samples**: https://github.com/webrtc/samples
- **Stack Overflow WebRTC**: https://stackoverflow.com/questions/tagged/webrtc
- **Dev.to WebRTC Articles**: https://dev.to/t/webrtc
- **CSS-Tricks Articles**: https://css-tricks.com/

### Tools & Resources

#### Development Tools
- **Chrome DevTools RTCStats**: chrome://webrtc-internals/
- **Postman API Client**: https://www.postman.com/
- **VS Code**: https://code.visualstudio.com/

#### Debugging WebRTC
- **WebRTC Troubleshooting Guide**: https://webrtc.org/troubleshooting/
- **Chrome WebRTC Internals**: chrome://webrtc-internals/
- **Firefox WebRTC Debugging**: about:about ‚Üí navigate to webrtc

#### TURN Servers (for Production)
- **Metered.ca** (free tier): https://www.metered.ca/
- **Twilio STUN/TURN**: https://www.twilio.com/stun-turn
- **Self-hosted coturn**: https://github.com/coturn/coturn

### Recommended Books & Courses

- **WebRTC: APIs and RTCWEB Protocols** by Salvatore Loreto
- **Real-Time Communication with WebRTC** by Sam Dutton
- **Udemy: WebRTC Mastery** course
- **Pluralsight: WebRTC for JavaScript Developers**

### Video Learning Resources

- **WebRTC Explained** (YouTube series): https://www.youtube.com/results?search_query=webrtc+explained
- **Google I/O WebRTC Talks**: https://www.youtube.com/results?search_query=google+io+webrtc
- **FireBase Setup Tutorials**: https://www.youtube.com/results?search_query=firebase+react+tutorial

---

## üéì Learning Path Summary

### Week 1: Foundations
- [ ] Understand WebRTC architecture and components
- [ ] Learn about STUN/TURN servers and NAT traversal
- [ ] Study SDP offer/answer model
- [ ] Complete basic React setup

### Week 2: Implementation
- [ ] Build peer connection component
- [ ] Implement signaling via Firebase
- [ ] Handle media streams (audio/video)
- [ ] Test local connections

### Week 3: Debugging & Refinement
- [ ] Handle ICE candidates
- [ ] Add proper error handling
- [ ] Test across different networks
- [ ] Implement fallbacks

### Week 4: Production
- [ ] Deploy to Netlify/Vercel
- [ ] Configure for production
- [ ] Monitor and optimize
- [ ] Gather user feedback

---

## ‚úÖ Completion Checklist

**Project Setup**
- [ ] Node.js and npm installed and verified
- [ ] Project cloned or extracted
- [ ] Firebase project created
- [ ] Firebase credentials obtained
- [ ] Environment variables configured

**Development**
- [ ] Dependencies installed (`npm install`)
- [ ] Development server running (`npm run dev`)
- [ ] First user registration successful
- [ ] Firestore collections populated with data
- [ ] WebRTC video call tested

**Deployment**
- [ ] Production build created (`npm run build`)
- [ ] Frontend deployed to Netlify/Vercel
- [ ] Firebase security rules configured
- [ ] TURN servers configured (for production)
- [ ] Analytics and monitoring set up

---

## üéØ Next Steps

1. **Immediate**: Follow QUICK_START.md for fastest setup
2. **Testing**: Create multiple accounts and test matching workflow
3. **Deployment**: Push to GitHub and deploy to Netlify
4. **Scaling**: Add more features from Toolkit Document
5. **Optimization**: Monitor performance and user feedback

---

**Document Version**: 1.0  
**Last Updated**: November 2025  
**Status**: Complete & Production Ready

**SkillSwap Africa: Exchange Skills, Unlock Potential üî•**
